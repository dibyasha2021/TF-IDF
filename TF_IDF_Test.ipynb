{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZVznlgAA0_7"
      },
      "outputs": [],
      "source": [
        " #importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "from nltk.tokenize import RegexpTokenizer,sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "773ojJ2qZyPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d32ee79-1a46-46dc-c90e-4d35dd584874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path=r\"/content/drive/MyDrive/Project & Research /NLP-Project/dataset /Final.csv\"\n",
        "TED_data=pd.read_csv(data_path)\n",
        "TED_data=TED_data.drop(columns=[\"Unnamed: 0\"],axis=1)\n",
        "TED_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "oLrmGmNqhWLe",
        "outputId": "b87d90e4-04d8-4cea-df0c-99ea09db1aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       document list  \\\n",
              "0  I have taken in many abandoned cats over the y...   \n",
              "1  This tea is just ok. Not offensive, but it doe...   \n",
              "2  I do not know what they were thinking with all...   \n",
              "3  I purchased this mat to go with the omega paw ...   \n",
              "4  I purchased this aquarium for my 2 year old's ...   \n",
              "5  Well, I was pleasantly surprised when I actual...   \n",
              "6  I just wanted to aknowledge a great customer e...   \n",
              "7  My wife and I love this gate! We live in an ex...   \n",
              "8  I have tried a LOT of automatic litter boxes o...   \n",
              "9  I love this thing. We bought it after our neig...   \n",
              "\n",
              "                                       sentence_list  Sentence_count  \\\n",
              "0  ['I have taken in many abandoned cats over the...              18   \n",
              "1  ['This tea is just ok', \" Not offensive, but i...              13   \n",
              "2  ['I do not know what they were thinking with a...              12   \n",
              "3  ['I purchased this mat to go with the omega pa...              12   \n",
              "4  [\"I purchased this aquarium for my 2 year old'...              12   \n",
              "5  [\"Well, I was pleasantly surprised when I actu...              12   \n",
              "6  ['I just wanted to aknowledge a great customer...              11   \n",
              "7  ['My wife and I love this gate! We live in an ...              11   \n",
              "8  ['I have tried a LOT of automatic litter boxes...              11   \n",
              "9  ['I love this thing', ' We bought it after our...              11   \n",
              "\n",
              "                                          one_String  \\\n",
              "0  I have taken in many abandoned cats over the y...   \n",
              "1  This tea is just ok  Not offensive, but it doe...   \n",
              "2  I do not know what they were thinking with all...   \n",
              "3  I purchased this mat to go with the omega paw ...   \n",
              "4  I purchased this aquarium for my 2 year old's ...   \n",
              "5  Well, I was pleasantly surprised when I actual...   \n",
              "6  I just wanted to aknowledge a great customer e...   \n",
              "7  My wife and I love this gate! We live in an ex...   \n",
              "8  I have tried a LOT of automatic litter boxes o...   \n",
              "9  I love this thing  We bought it after our neig...   \n",
              "\n",
              "                               documents_removepunct  \\\n",
              "0  I have taken in many abandoned cats over the y...   \n",
              "1  This tea is just ok  Not offensive but it does...   \n",
              "2  I do not know what they were thinking with all...   \n",
              "3  I purchased this mat to go with the omega paw ...   \n",
              "4  I purchased this aquarium for my 2 year olds g...   \n",
              "5  Well I was pleasantly surprised when I actuall...   \n",
              "6  I just wanted to aknowledge a great customer e...   \n",
              "7  My wife and I love this gate We live in an ext...   \n",
              "8  I have tried a LOT of automatic litter boxes o...   \n",
              "9  I love this thing  We bought it after our neig...   \n",
              "\n",
              "                                lower_cased_document  \\\n",
              "0  i have taken in many abandoned cats over the y...   \n",
              "1  this tea is just ok  not offensive but it does...   \n",
              "2  i do not know what they were thinking with all...   \n",
              "3  i purchased this mat to go with the omega paw ...   \n",
              "4  i purchased this aquarium for my 2 year olds g...   \n",
              "5  well i was pleasantly surprised when i actuall...   \n",
              "6  i just wanted to aknowledge a great customer e...   \n",
              "7  my wife and i love this gate we live in an ext...   \n",
              "8  i have tried a lot of automatic litter boxes o...   \n",
              "9  i love this thing  we bought it after our neig...   \n",
              "\n",
              "                                     tokennized_docs  \\\n",
              "0  ['i', 'have', 'taken', 'in', 'many', 'abandone...   \n",
              "1  ['this', 'tea', 'is', 'just', 'ok', 'not', 'of...   \n",
              "2  ['i', 'do', 'not', 'know', 'what', 'they', 'we...   \n",
              "3  ['i', 'purchased', 'this', 'mat', 'to', 'go', ...   \n",
              "4  ['i', 'purchased', 'this', 'aquarium', 'for', ...   \n",
              "5  ['well', 'i', 'wa', 'pleasantly', 'surprised',...   \n",
              "6  ['i', 'just', 'wanted', 'to', 'aknowledge', 'a...   \n",
              "7  ['my', 'wife', 'and', 'i', 'love', 'this', 'ga...   \n",
              "8  ['i', 'have', 'tried', 'a', 'lot', 'of', 'auto...   \n",
              "9  ['i', 'love', 'this', 'thing', 'we', 'bought',...   \n",
              "\n",
              "                                        no_stopwords  \n",
              "0  ['taken', 'abandoned', 'cat', 'year', 'product...  \n",
              "1  ['tea', 'ok', 'offensive', 'doesnt', 'taste', ...  \n",
              "2  ['know', 'thinking', 'reformulations', 'excell...  \n",
              "3  ['purchased', 'mat', 'omega', 'paw', 'roll', '...  \n",
              "4  ['purchased', 'aquarium', '2', 'year', 'old', ...  \n",
              "5  ['wa', 'pleasantly', 'surprised', 'actually', ...  \n",
              "6  ['wanted', 'aknowledge', 'great', 'customer', ...  \n",
              "7  ['wife', 'love', 'gate', 'live', 'extremely', ...  \n",
              "8  ['tried', 'lot', 'automatic', 'litter', 'box',...  \n",
              "9  ['love', 'thing', 'bought', 'neighbor', 'rente...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61a9535f-681d-411b-b007-e689861465d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document list</th>\n",
              "      <th>sentence_list</th>\n",
              "      <th>Sentence_count</th>\n",
              "      <th>one_String</th>\n",
              "      <th>documents_removepunct</th>\n",
              "      <th>lower_cased_document</th>\n",
              "      <th>tokennized_docs</th>\n",
              "      <th>no_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have taken in many abandoned cats over the y...</td>\n",
              "      <td>['I have taken in many abandoned cats over the...</td>\n",
              "      <td>18</td>\n",
              "      <td>I have taken in many abandoned cats over the y...</td>\n",
              "      <td>I have taken in many abandoned cats over the y...</td>\n",
              "      <td>i have taken in many abandoned cats over the y...</td>\n",
              "      <td>['i', 'have', 'taken', 'in', 'many', 'abandone...</td>\n",
              "      <td>['taken', 'abandoned', 'cat', 'year', 'product...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This tea is just ok. Not offensive, but it doe...</td>\n",
              "      <td>['This tea is just ok', \" Not offensive, but i...</td>\n",
              "      <td>13</td>\n",
              "      <td>This tea is just ok  Not offensive, but it doe...</td>\n",
              "      <td>This tea is just ok  Not offensive but it does...</td>\n",
              "      <td>this tea is just ok  not offensive but it does...</td>\n",
              "      <td>['this', 'tea', 'is', 'just', 'ok', 'not', 'of...</td>\n",
              "      <td>['tea', 'ok', 'offensive', 'doesnt', 'taste', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I do not know what they were thinking with all...</td>\n",
              "      <td>['I do not know what they were thinking with a...</td>\n",
              "      <td>12</td>\n",
              "      <td>I do not know what they were thinking with all...</td>\n",
              "      <td>I do not know what they were thinking with all...</td>\n",
              "      <td>i do not know what they were thinking with all...</td>\n",
              "      <td>['i', 'do', 'not', 'know', 'what', 'they', 'we...</td>\n",
              "      <td>['know', 'thinking', 'reformulations', 'excell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I purchased this mat to go with the omega paw ...</td>\n",
              "      <td>['I purchased this mat to go with the omega pa...</td>\n",
              "      <td>12</td>\n",
              "      <td>I purchased this mat to go with the omega paw ...</td>\n",
              "      <td>I purchased this mat to go with the omega paw ...</td>\n",
              "      <td>i purchased this mat to go with the omega paw ...</td>\n",
              "      <td>['i', 'purchased', 'this', 'mat', 'to', 'go', ...</td>\n",
              "      <td>['purchased', 'mat', 'omega', 'paw', 'roll', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I purchased this aquarium for my 2 year old's ...</td>\n",
              "      <td>[\"I purchased this aquarium for my 2 year old'...</td>\n",
              "      <td>12</td>\n",
              "      <td>I purchased this aquarium for my 2 year old's ...</td>\n",
              "      <td>I purchased this aquarium for my 2 year olds g...</td>\n",
              "      <td>i purchased this aquarium for my 2 year olds g...</td>\n",
              "      <td>['i', 'purchased', 'this', 'aquarium', 'for', ...</td>\n",
              "      <td>['purchased', 'aquarium', '2', 'year', 'old', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Well, I was pleasantly surprised when I actual...</td>\n",
              "      <td>[\"Well, I was pleasantly surprised when I actu...</td>\n",
              "      <td>12</td>\n",
              "      <td>Well, I was pleasantly surprised when I actual...</td>\n",
              "      <td>Well I was pleasantly surprised when I actuall...</td>\n",
              "      <td>well i was pleasantly surprised when i actuall...</td>\n",
              "      <td>['well', 'i', 'wa', 'pleasantly', 'surprised',...</td>\n",
              "      <td>['wa', 'pleasantly', 'surprised', 'actually', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I just wanted to aknowledge a great customer e...</td>\n",
              "      <td>['I just wanted to aknowledge a great customer...</td>\n",
              "      <td>11</td>\n",
              "      <td>I just wanted to aknowledge a great customer e...</td>\n",
              "      <td>I just wanted to aknowledge a great customer e...</td>\n",
              "      <td>i just wanted to aknowledge a great customer e...</td>\n",
              "      <td>['i', 'just', 'wanted', 'to', 'aknowledge', 'a...</td>\n",
              "      <td>['wanted', 'aknowledge', 'great', 'customer', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>My wife and I love this gate! We live in an ex...</td>\n",
              "      <td>['My wife and I love this gate! We live in an ...</td>\n",
              "      <td>11</td>\n",
              "      <td>My wife and I love this gate! We live in an ex...</td>\n",
              "      <td>My wife and I love this gate We live in an ext...</td>\n",
              "      <td>my wife and i love this gate we live in an ext...</td>\n",
              "      <td>['my', 'wife', 'and', 'i', 'love', 'this', 'ga...</td>\n",
              "      <td>['wife', 'love', 'gate', 'live', 'extremely', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I have tried a LOT of automatic litter boxes o...</td>\n",
              "      <td>['I have tried a LOT of automatic litter boxes...</td>\n",
              "      <td>11</td>\n",
              "      <td>I have tried a LOT of automatic litter boxes o...</td>\n",
              "      <td>I have tried a LOT of automatic litter boxes o...</td>\n",
              "      <td>i have tried a lot of automatic litter boxes o...</td>\n",
              "      <td>['i', 'have', 'tried', 'a', 'lot', 'of', 'auto...</td>\n",
              "      <td>['tried', 'lot', 'automatic', 'litter', 'box',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I love this thing. We bought it after our neig...</td>\n",
              "      <td>['I love this thing', ' We bought it after our...</td>\n",
              "      <td>11</td>\n",
              "      <td>I love this thing  We bought it after our neig...</td>\n",
              "      <td>I love this thing  We bought it after our neig...</td>\n",
              "      <td>i love this thing  we bought it after our neig...</td>\n",
              "      <td>['i', 'love', 'this', 'thing', 'we', 'bought',...</td>\n",
              "      <td>['love', 'thing', 'bought', 'neighbor', 'rente...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61a9535f-681d-411b-b007-e689861465d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61a9535f-681d-411b-b007-e689861465d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61a9535f-681d-411b-b007-e689861465d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list od documents\n",
        "documents=[]\n",
        "for y in range(10): \n",
        "  doc=TED_data.iloc[y][\"documents_removepunct\"]\n",
        "  documents.append(doc)\n",
        "print(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC1QbwbpGTwT",
        "outputId": "48c4e1cc-98ba-438a-8b35-911e3439bfaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I have taken in many abandoned cats over the years and this is what I give them  This product is the generic version of the stuff you get from the vet  VERY EFFECTIVE Usually goes away in one treatment  Sometimes I give two treatments just to be sure I live in a mobile home park where pets are allowed  Everyone has a pet and the parasites are in the soil  I keep this product in stock at home  The first sign of tapeworms and this stuff comes out of the cabinet  I have to medicate one of my cats for hyperthyroidism so I useGreenies Pill Pockets for Cats Salmon 1 6 ounce  Cats love them You will never have to force down a pill again Place 12 tablet per 1 pill pocket  No struggling  No fuss  Also in chicken and duck flavor Tapeworms come from fleas so use a good flea med too  Make sure to vacuum carpets and pet areas and wash all bedding  I like to clean the cat box and replace the litter also to reduce the possibility of reinfestation  Oh yeah dont forget the cardboard cat scratchers its a good time to replace them', 'This tea is just ok  Not offensive but it doesnt really have much taste  I was really surprised when I first drank it  I think the best way I can describe the taste is starchy  Like if you cooked white rice in water for a while but then dumped out the rice and just drank the water  Not much of a taste but just kind of a starchy flavor  I guess this herb is supposed to help clean your liver but who can really say how much benefit its having I dont have any specific liver problems but I just like to try a variety of different herbal formulations to get the benefits of items that dont get consumed in the normal daily diet  I drink herbal tea for health but also as a tasty beverage  I probably wont get this one again Ill probably move on to some other herb next  There are a million out there and its nice to mix them up and expose yourself to a variety of different ones to help your overall health  But they have to be a more of a standout to make it into my regular rotation  This one didnt really make the cut  Sorry Milk Thistle', 'I do not know what they were thinking with all of these reformulations of what were once excellent products  I have written about the preshave that if you have never used it before you will probably like it but if you have you will be extremely disappointed with the new formulation  With the aftershave I do not think anyone could really think this is anything but a disaster for Proraso At first glance there is not much change  It is slightly lighter in color and thinner than the original probably necessary for it to flow out of the new squaredcorner flattop bottle designthats right no more cool reusable flask  It is slightly more watery and does not feel quite as good to the skin as the original formulation but this is a minor issue  The real problem is the godawful smell  It reminds me of my grandmas bathroomnot sure if it was the rose toilet water or the Glade air freshenerbut it is putrid  Use it if you want to smell like an old woman all day  Otherwise there are plenty of options that not only smell better but also work better than this formulation Next week I will be opening my new formulation shaving soap  If the preshave and aftershave are any indication I might as well go back to Barbasol and disposable razors', 'I purchased this mat to go with the omega paw roll away cat litter pan  I love the color and look of this cat mat  It is easier to clean than the cloth type you see in most pet stores  It is a bit small so litter still tracks with this mat  It is still however the best mat Ive ever purchased for my cats and they have had at least a dozen  Even after two or three years of use this mat still looks relatively new  Its easy to clean as well  I wash it in conjunction with the litter pan  I just soak it inside the litter pan with warm soapy water  It does take some time to dry though  I am deducting one star for its size  It does not even cover the entrance of most large cat pans', 'I purchased this aquarium for my 2 year olds goldfish  It seemed like a good design in the store Also didnt read many negative reviews  All integrated filter and water circulator  great They tellyou to replace the filter every week or few weeks so they make a nice little door on the cover forthe purpose  Then I went to feed the fish Theres no way to feed the fish through the cover  Youhave to lift the entire lid off and drop in the food then realign the lid on the base  Lame Why wouldsomeone design something to be convenient for an occasional inconvenience and not designanything for a task done daily or more After emailing the company first to question the designI was told in response to lift the filter changing door and feed through there  Great They give a halfinch of clearance with a crossbar in the way  So I can barely drop in some food and it lands on thecrossbar getting nasty  When I responded much like my review I never heard back  I guess thecompany agrees with me and were speechless Well see if the next design actually makes moresense for the user and not the designer', 'Well I was pleasantly surprised when I actually enjoyed this scent as Ive detested most of J  Los scents  Live Luxe is the first followup to Live  It is a fruity floral created by perfumer Claudette Belnavis  The notes include pear peach melon apple muguet amethyst freesia honeysuckle diamond musk amber vanilla and sandalwood Personally I find Live Luxe zesty light and clean  It smells very feminine and carefree  When I wear Live Luxe it actually relaxes me  Live Luxe isnt the usual fragrance that Im drawn to but I like this one not love  Live Luxe is also good for layering with CSPs Vanille Canelle  The Vanille Canelle gives it a stronger base with a bit more depth I wouldnt repurchase this as its not in the fragrance family that Im drawn to but its worth a try', 'I just wanted to aknowledge a great customer experience  Everyone knows that Britax makes excellent products and the Marathon is no exception  The only real problem is with the price Marathons are expensive  So when I had an opportunity to get the Marathon at a great clearance price of 80 off I jumped on the opportunity and placed my order Then a week or so later I get the letter saying that my car seat was no longer available and that my order would be cancelled  Anger turned to surprise when a week later I received another email that stated I would could buy the similar Onyx style for the same price  That is great customer service  You would think a big online retailer would just blow you off but they didnt If I can point to any flaw on the Britax I would just reccommend that they consider a more micro fiber style fabric for the car seat like I have on my Evenflo Triumph  IT feels a bit more luxurious  But the seat is very comfortable for my son and easy to install', 'My wife and I love this gate We live in an extremely old house and did not want to purchase a gate that required screws or related permanent fixtures  We had also gotten extremely weary of hurdling the previous gate or having to put down our son to open it  When we purchased this in our local Target the set came with the additional extension  With the extension in place I was able to easily snug up the gate using the included wrench  Even though our door opening is only 37148 the extension was crucial in insuring that the gate was the immoveable object that we needed  I read very early reviews pre2003 that spoke of flimsiness in the foot pedal but I can only assume that the problem has been fixed  I do not have a light touch and we use this gate in a high traffic area  In spite of that however I have noted no weakness in the pedal  If anything the pedal has gotten firmer over time  My son 19 months 28 lbs has figured out how mommy and daddy get through the gate and while he has started to try jumping up and down on the pedal he has yet to be able to open it  Hope you enjoy it as much as we have', 'I have tried a LOT of automatic litter boxes over the years always searching for the best  This is actually the second ScoopFree for me  The first one lasted maybe 45 years with a 23 cat household and a lot of use  A clean litter box is a must if it isnt clean my female wont go near it this system makes it so easy to do  I love that it is easy to change you just tilt the box up take out the old and replace with the new  It is also very easy to clean the box itself I just wipe down the box when I change the trays  I have a kitty that in every other box I have tried piles up the litter which ends up wasting a lot of it when they rake across that doesnt happen at all with the ScoopFree  For me I only get a week or 10 days out of each tray but I have two elderly cats who make extra urine due to a few health issues  I get my trays in bulk from the scoop free website it is a great deal  My one issue with my previous box was that the rake rusted and was very yucky  Overall a great litter box system and I highly recommend it', 'I love this thing  We bought it after our neighbor rented out his house to people with large constantly barking dogs  Our 7monthold son can now get his nap again  I find it soothing as well  Unlike just using a fan or a humidifier it can be adjusted to make sure it hums at a low frequency but with enough volume to really help in an urban situation like ours  The two speeds are great and I go back and forth between them depending on what I am trying to tune out  It even makes losers with their loud car stereos blaring more bearable  You can still hear really loud things through it I do want to hear the phone for instance but it takes the edge off  It really does reduce stress and makes it easier to sleep or stay asleep dispite the unnecessary noise of inconsiderate neighbors  Even when we move to a better neighborhood I am still going to use it because I find it so relaxing  Combine it with a variable sound like waves crashing like on many alarm clock models and the baby has a total womblike sound environment  better than those womb sound machines because it does not annoy Mommy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list of words in douments\n",
        "All_words=[]\n",
        "for y in range(10):\n",
        "  documents=TED_data.iloc[y][\"no_stopwords\"]\n",
        "  All_words.append(eval(documents))\n",
        "print(All_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvbghiEYyPL2",
        "outputId": "ee1ff309-902a-473f-c8be-c3ee732f4efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['taken', 'abandoned', 'cat', 'year', 'product', 'generic', 'version', 'stuff', 'vet', 'effective', 'usually', 'away', 'treatment', 'treatment', 'sure', 'live', 'mobile', 'home', 'park', 'pet', 'allowed', 'ha', 'pet', 'parasite', 'soil', 'product', 'stock', 'home', 'sign', 'tapeworm', 'stuff', 'come', 'cabinet', 'medicate', 'cat', 'hyperthyroidism', 'usegreenies', 'pill', 'pocket', 'cat', 'salmon', '1', '6', 'ounce', 'cat', 'love', 'force', 'pill', 'place', '12', 'tablet', '1', 'pill', 'pocket', 'struggling', 'fuss', 'chicken', 'duck', 'flavor', 'tapeworm', 'come', 'flea', 'use', 'good', 'flea', 'med', 'sure', 'vacuum', 'carpet', 'pet', 'area', 'wash', 'bedding', 'like', 'clean', 'cat', 'box', 'replace', 'litter', 'reduce', 'possibility', 'reinfestation', 'oh', 'yeah', 'dont', 'forget', 'cardboard', 'cat', 'scratcher', 'good', 'time', 'replace'], ['tea', 'ok', 'offensive', 'doesnt', 'taste', 'wa', 'surprised', 'drank', 'think', 'best', 'way', 'taste', 'starchy', 'like', 'cooked', 'white', 'rice', 'water', 'dumped', 'rice', 'drank', 'water', 'taste', 'kind', 'starchy', 'flavor', 'guess', 'herb', 'supposed', 'help', 'clean', 'liver', 'benefit', 'having', 'dont', 'specific', 'liver', 'problem', 'like', 'try', 'variety', 'different', 'herbal', 'formulation', 'benefit', 'item', 'dont', 'consumed', 'normal', 'daily', 'diet', 'drink', 'herbal', 'tea', 'health', 'tasty', 'beverage', 'probably', 'wont', 'ill', 'probably', 'herb', 'million', 'nice', 'mix', 'expose', 'variety', 'different', 'help', 'overall', 'health', 'standout', 'regular', 'rotation', 'didnt', 'cut', 'sorry', 'milk', 'thistle'], ['know', 'thinking', 'reformulations', 'excellent', 'product', 'written', 'preshave', 'probably', 'like', 'extremely', 'disappointed', 'new', 'formulation', 'aftershave', 'think', 'think', 'disaster', 'proraso', 'glance', 'change', 'slightly', 'lighter', 'color', 'thinner', 'original', 'probably', 'necessary', 'flow', 'new', 'squaredcorner', 'flattop', 'bottle', 'designthats', 'right', 'cool', 'reusable', 'flask', 'slightly', 'watery', 'doe', 'feel', 'good', 'skin', 'original', 'formulation', 'minor', 'issue', 'real', 'problem', 'godawful', 'smell', 'reminds', 'grandma', 'bathroomnot', 'sure', 'wa', 'rose', 'toilet', 'water', 'glade', 'air', 'freshenerbut', 'putrid', 'use', 'want', 'smell', 'like', 'old', 'woman', 'day', 'plenty', 'option', 'smell', 'better', 'work', 'better', 'formulation', 'week', 'opening', 'new', 'formulation', 'shaving', 'soap', 'preshave', 'aftershave', 'indication', 'barbasol', 'disposable', 'razor'], ['purchased', 'mat', 'omega', 'paw', 'roll', 'away', 'cat', 'litter', 'pan', 'love', 'color', 'look', 'cat', 'mat', 'easier', 'clean', 'cloth', 'type', 'pet', 'store', 'bit', 'small', 'litter', 'track', 'mat', 'best', 'mat', 'ive', 'purchased', 'cat', 'dozen', 'year', 'use', 'mat', 'look', 'relatively', 'new', 'easy', 'clean', 'wash', 'conjunction', 'litter', 'pan', 'soak', 'inside', 'litter', 'pan', 'warm', 'soapy', 'water', 'doe', 'time', 'dry', 'deducting', 'star', 'size', 'doe', 'cover', 'entrance', 'large', 'cat', 'pan'], ['purchased', 'aquarium', '2', 'year', 'old', 'goldfish', 'like', 'good', 'design', 'store', 'didnt', 'read', 'negative', 'review', 'integrated', 'filter', 'water', 'circulator', 'great', 'tellyou', 'replace', 'filter', 'week', 'week', 'nice', 'little', 'door', 'cover', 'forthe', 'purpose', 'went', 'feed', 'fish', 'way', 'feed', 'fish', 'cover', 'youhave', 'lift', 'entire', 'lid', 'drop', 'food', 'realign', 'lid', 'base', 'lame', 'wouldsomeone', 'design', 'convenient', 'occasional', 'inconvenience', 'designanything', 'task', 'daily', 'emailing', 'company', 'question', 'designi', 'wa', 'told', 'response', 'lift', 'filter', 'changing', 'door', 'feed', 'great', 'halfinch', 'clearance', 'crossbar', 'way', 'barely', 'drop', 'food', 'land', 'thecrossbar', 'getting', 'nasty', 'responded', 'like', 'review', 'heard', 'guess', 'thecompany', 'agrees', 'speechless', 'design', 'actually', 'moresense', 'user', 'designer'], ['wa', 'pleasantly', 'surprised', 'actually', 'enjoyed', 'scent', 'ive', 'detested', 'j', 'los', 'scent', 'live', 'luxe', 'followup', 'live', 'fruity', 'floral', 'created', 'perfumer', 'claudette', 'belnavis', 'note', 'include', 'pear', 'peach', 'melon', 'apple', 'muguet', 'amethyst', 'freesia', 'honeysuckle', 'diamond', 'musk', 'amber', 'vanilla', 'sandalwood', 'personally', 'live', 'luxe', 'zesty', 'light', 'clean', 'smell', 'feminine', 'carefree', 'wear', 'live', 'luxe', 'actually', 'relaxes', 'live', 'luxe', 'isnt', 'usual', 'fragrance', 'im', 'drawn', 'like', 'love', 'live', 'luxe', 'good', 'layering', 'csps', 'vanille', 'canelle', 'vanille', 'canelle', 'stronger', 'base', 'bit', 'depth', 'wouldnt', 'repurchase', 'fragrance', 'family', 'im', 'drawn', 'worth', 'try'], ['wanted', 'aknowledge', 'great', 'customer', 'experience', 'know', 'britax', 'excellent', 'product', 'marathon', 'exception', 'real', 'problem', 'price', 'marathon', 'expensive', 'opportunity', 'marathon', 'great', 'clearance', 'price', '80', 'jumped', 'opportunity', 'placed', 'order', 'week', 'later', 'letter', 'saying', 'car', 'seat', 'wa', 'longer', 'available', 'order', 'cancelled', 'anger', 'turned', 'surprise', 'week', 'later', 'received', 'email', 'stated', 'buy', 'similar', 'onyx', 'style', 'price', 'great', 'customer', 'service', 'think', 'big', 'online', 'retailer', 'blow', 'didnt', 'point', 'flaw', 'britax', 'reccommend', 'consider', 'micro', 'fiber', 'style', 'fabric', 'car', 'seat', 'like', 'evenflo', 'triumph', 'feel', 'bit', 'luxurious', 'seat', 'comfortable', 'son', 'easy', 'install'], ['wife', 'love', 'gate', 'live', 'extremely', 'old', 'house', 'want', 'purchase', 'gate', 'required', 'screw', 'related', 'permanent', 'fixture', 'gotten', 'extremely', 'weary', 'hurdling', 'previous', 'gate', 'having', 'son', 'open', 'purchased', 'local', 'target', 'set', 'came', 'additional', 'extension', 'extension', 'place', 'wa', 'able', 'easily', 'snug', 'gate', 'included', 'wrench', 'door', 'opening', '37148', 'extension', 'wa', 'crucial', 'insuring', 'gate', 'wa', 'immoveable', 'object', 'needed', 'read', 'early', 'review', 'pre2003', 'spoke', 'flimsiness', 'foot', 'pedal', 'assume', 'problem', 'ha', 'fixed', 'light', 'touch', 'use', 'gate', 'high', 'traffic', 'area', 'spite', 'noted', 'weakness', 'pedal', 'pedal', 'ha', 'gotten', 'firmer', 'time', 'son', '19', 'month', '28', 'lb', 'ha', 'figured', 'mommy', 'daddy', 'gate', 'ha', 'started', 'try', 'jumping', 'pedal', 'ha', 'able', 'open', 'hope', 'enjoy'], ['tried', 'lot', 'automatic', 'litter', 'box', 'year', 'searching', 'best', 'actually', 'second', 'scoopfree', 'lasted', 'maybe', '45', 'year', '23', 'cat', 'household', 'lot', 'use', 'clean', 'litter', 'box', 'isnt', 'clean', 'female', 'wont', 'near', 'easy', 'love', 'easy', 'change', 'tilt', 'box', 'old', 'replace', 'new', 'easy', 'clean', 'box', 'wipe', 'box', 'change', 'tray', 'kitty', 'box', 'tried', 'pile', 'litter', 'end', 'wasting', 'lot', 'rake', 'doesnt', 'happen', 'scoopfree', 'week', '10', 'day', 'tray', 'elderly', 'cat', 'extra', 'urine', 'health', 'issue', 'tray', 'bulk', 'scoop', 'free', 'website', 'great', 'deal', 'issue', 'previous', 'box', 'wa', 'rake', 'rusted', 'wa', 'yucky', 'overall', 'great', 'litter', 'box', 'highly', 'recommend'], ['love', 'thing', 'bought', 'neighbor', 'rented', 'house', 'people', 'large', 'constantly', 'barking', 'dog', '7monthold', 'son', 'nap', 'soothing', 'unlike', 'fan', 'humidifier', 'adjusted', 'sure', 'hum', 'low', 'frequency', 'volume', 'help', 'urban', 'situation', 'like', 'speed', 'great', 'forth', 'depending', 'trying', 'tune', 'loser', 'loud', 'car', 'stereo', 'blaring', 'bearable', 'hear', 'loud', 'thing', 'want', 'hear', 'phone', 'instance', 'edge', 'doe', 'reduce', 'stress', 'easier', 'sleep', 'stay', 'asleep', 'dispite', 'unnecessary', 'noise', 'inconsiderate', 'neighbor', 'better', 'neighborhood', 'going', 'use', 'relaxing', 'combine', 'variable', 'sound', 'like', 'wave', 'crashing', 'like', 'alarm', 'clock', 'model', 'baby', 'ha', 'total', 'womblike', 'sound', 'environment', 'better', 'womb', 'sound', 'machine', 'doe', 'annoy', 'mommy']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#finding Unique words in all  the documents\n",
        "def Unique_words(list_of_tokens):\n",
        "  n=len(list_of_tokens)\n",
        "  s=1\n",
        "  wordset=set(list_of_tokens[0])\n",
        "  while s<n:\n",
        "    wordset=wordset.union(set(list_of_tokens[s]))\n",
        "    s=s+1\n",
        "  return wordset\n",
        "\n",
        "word_list=[]\n",
        "for x in range(10): \n",
        "  word_list.append(eval(TED_data.iloc[x][\"no_stopwords\"]))\n",
        "\n",
        "# set of unique words\n",
        "Uniq_words=Unique_words(word_list)"
      ],
      "metadata": {
        "id": "OyMPFfcP0BHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Bag of words\n",
        "def calculateBOW(wordset,doc):\n",
        "  tf_diz = dict.fromkeys(wordset,0)\n",
        "  for word in doc:\n",
        "      tf_diz[word]=doc.count(word)\n",
        "  return tf_diz\n"
      ],
      "metadata": {
        "id": "fE56kziMsRD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BOW of All doc\n",
        "Bag_of_words=[]\n",
        "for doc in All_words:\n",
        "    Bag_of_words.append(calculateBOW(Uniq_words,doc))\n",
        "#Bag_of_words"
      ],
      "metadata": {
        "id": "B0TWFLVlOvbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataframe of the given Bag of words\n",
        "#for single doc replace Bag_of_words--> Bag_of_words_single\n",
        "df_bow_all = pd.DataFrame(Bag_of_words)\n",
        "BOW_all=df_bow_all.T\n",
        "BOW_all\n"
      ],
      "metadata": {
        "id": "Q5hJOEWp39DF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "293d0cee-df84-4e4d-bf94-f489fd151c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0  1  2  3  4  5  6  7  8  9\n",
              "fixture   0  0  0  0  0  0  0  1  0  0\n",
              "female    0  0  0  0  0  0  0  0  1  0\n",
              "watery    0  0  1  0  0  0  0  0  0  0\n",
              "milk      0  1  0  0  0  0  0  0  0  0\n",
              "grandma   0  0  1  0  0  0  0  0  0  0\n",
              "...      .. .. .. .. .. .. .. .. .. ..\n",
              "noted     0  0  0  0  0  0  0  1  0  0\n",
              "daddy     0  0  0  0  0  0  0  1  0  0\n",
              "bearable  0  0  0  0  0  0  0  0  0  1\n",
              "carefree  0  0  0  0  0  1  0  0  0  0\n",
              "house     0  0  0  0  0  0  0  1  0  1\n",
              "\n",
              "[533 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49e77a64-e161-4187-a43c-cc1e1b509c7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fixture</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>female</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>watery</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>milk</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grandma</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>noted</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>daddy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bearable</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carefree</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>house</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>533 rows  10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49e77a64-e161-4187-a43c-cc1e1b509c7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49e77a64-e161-4187-a43c-cc1e1b509c7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49e77a64-e161-4187-a43c-cc1e1b509c7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Term frequency function\n",
        "def termFrequency(term, doc):\n",
        "    # Splitting the document into individual terms\n",
        "    normalizeTermFreq = doc.lower().split()\n",
        " \n",
        "    # Number of times the term occurs in the document\n",
        "    term_in_document = normalizeTermFreq.count(term.lower())\n",
        " \n",
        "    # Total number of terms in the document\n",
        "    len_of_document = float(len(normalizeTermFreq ))\n",
        " \n",
        "    # Normalized Term Frequency\n",
        "    normalized_tf = term_in_document / len_of_document\n",
        " \n",
        "    return normalized_tf"
      ],
      "metadata": {
        "id": "wgvpn3Hf4Wt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "All_docs=[]\n",
        "for y in range(10):\n",
        "  doc=TED_data.iloc[y][\"lower_cased_document\"]\n",
        "  All_docs.append(doc)\n",
        "print(len(All_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia5A_EZ_KKw9",
        "outputId": "ac41ea55-a4fc-4574-c635-5c1e7274e855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TF of the given word in documents[0]\n",
        "termFrequency('generic',All_docs[0])"
      ],
      "metadata": {
        "id": "5l77sNdu40H4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e85b63-5671-49e0-ca96-7d5bda137080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005050505050505051"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#finding Term frequency of each unique words\n",
        "def Termfreq_all(unique_words,AllDoc):\n",
        "  tf_word={}\n",
        "  \n",
        "  for token in unique_words:\n",
        "    tf_list_docwise=[]\n",
        "    for doc in AllDoc:\n",
        "      tf_list_docwise.append(termFrequency(token,doc))\n",
        "    \n",
        "    tf_word[token]=tf_list_docwise\n",
        "        \n",
        "  return tf_word\n",
        "#Termfreq_all(Uniq_words,All_docs)"
      ],
      "metadata": {
        "id": "Nb2E__6y42ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF of each word in all the Documents\n",
        "tf_word=Termfreq_all(Uniq_words,All_docs)\n",
        "#tf_word"
      ],
      "metadata": {
        "id": "KO9xe8q75KwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Inverse Document Frequency -idf\n",
        "def IDF(corpus, unique_words):\n",
        "   idf_dict={}\n",
        "   N=len(corpus)\n",
        "   for i in unique_words:\n",
        "     count=0\n",
        "     for sen in corpus:\n",
        "       if i in sen.lower().split():\n",
        "         count=count+1\n",
        "       idf_dict[i]=(math.log((1+N)/(count+1)))+1\n",
        "   return idf_dict "
      ],
      "metadata": {
        "id": "tLYrIqZ45Q2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IDF of each for all the documents cumulatively \n",
        "#print(documents)\n",
        "idf=IDF(documents,Uniq_words)\n",
        "#idf"
      ],
      "metadata": {
        "id": "i1KBky115b8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF score each term in a given document\n",
        "tf=termFrequency('generic',All_docs[0])\n",
        "idf_term=idf['generic']\n",
        "Score=tf*idf_term\n",
        "print(Score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pu6e_4J5eZ7",
        "outputId": "9e783aa2-ad90-414d-98be-d5bf39c228c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03917055011103159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Score wor all unique words \n",
        "def Score(unique_words,Docs):\n",
        "  idf=IDF(Docs,unique_words)\n",
        "  #print(idf)\n",
        "  #print(len(eval(Docs)))\n",
        "  score={}\n",
        "  for token in unique_words:\n",
        "    Score=[]\n",
        "    for doc in Docs:\n",
        "      #print(doc)\n",
        "      tf=termFrequency(token,doc)\n",
        "      Score.append(tf*idf[token])\n",
        "\n",
        "    score[token]=Score\n",
        "  return score\n",
        "final_score=Score(Uniq_words,All_docs)"
      ],
      "metadata": {
        "id": "tnCScIxF518x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to get the TF-IDF score value document wise\n",
        "FS_df=pd.DataFrame.from_dict(final_score,orient=\"index\")\n",
        "FS_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "f0v3Npn89OMM",
        "outputId": "87018a71-053a-47c6-b0f9-76a2c701f8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0        1         2    3    4         5    6         7         8  \\\n",
              "fixture   0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.000000   \n",
              "female    0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.012294   \n",
              "watery    0.0  0.00000  0.012021  0.0  0.0  0.000000  0.0  0.000000  0.000000   \n",
              "milk      0.0  0.01313  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.000000   \n",
              "grandma   0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.000000   \n",
              "...       ...      ...       ...  ...  ...       ...  ...       ...       ...   \n",
              "noted     0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.012294  0.000000   \n",
              "daddy     0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.012294  0.000000   \n",
              "bearable  0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.000000   \n",
              "carefree  0.0  0.00000  0.000000  0.0  0.0  0.019459  0.0  0.000000  0.000000   \n",
              "house     0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.010451  0.000000   \n",
              "\n",
              "                 9  \n",
              "fixture   0.000000  \n",
              "female    0.000000  \n",
              "watery    0.000000  \n",
              "milk      0.000000  \n",
              "grandma   0.000000  \n",
              "...            ...  \n",
              "noted     0.000000  \n",
              "daddy     0.000000  \n",
              "bearable  0.013130  \n",
              "carefree  0.000000  \n",
              "house     0.011162  \n",
              "\n",
              "[533 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1c028ca-3b22-4f0e-9b69-5fbc7ebeb953\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fixture</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>female</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012294</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>watery</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.012021</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>milk</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01313</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grandma</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>noted</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>daddy</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bearable</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carefree</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>house</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011162</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>533 rows  10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1c028ca-3b22-4f0e-9b69-5fbc7ebeb953')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1c028ca-3b22-4f0e-9b69-5fbc7ebeb953 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1c028ca-3b22-4f0e-9b69-5fbc7ebeb953');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=FS_df.sort_values(by=4,ascending=False)\n",
        "result.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "JTG2v0icroaC",
        "outputId": "e319e2b4-e51a-418e-aa13-144e829d289d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1    2    3         4    5    6         7    8    9\n",
              "design  0.0  0.000000  0.0  0.0  0.040571  0.0  0.0  0.000000  0.0  0.0\n",
              "filter  0.0  0.000000  0.0  0.0  0.040571  0.0  0.0  0.000000  0.0  0.0\n",
              "feed    0.0  0.000000  0.0  0.0  0.040571  0.0  0.0  0.000000  0.0  0.0\n",
              "lid     0.0  0.000000  0.0  0.0  0.027047  0.0  0.0  0.000000  0.0  0.0\n",
              "lift    0.0  0.000000  0.0  0.0  0.027047  0.0  0.0  0.000000  0.0  0.0\n",
              "fish    0.0  0.000000  0.0  0.0  0.027047  0.0  0.0  0.000000  0.0  0.0\n",
              "drop    0.0  0.000000  0.0  0.0  0.027047  0.0  0.0  0.000000  0.0  0.0\n",
              "food    0.0  0.000000  0.0  0.0  0.027047  0.0  0.0  0.000000  0.0  0.0\n",
              "way     0.0  0.011162  0.0  0.0  0.022993  0.0  0.0  0.000000  0.0  0.0\n",
              "door    0.0  0.000000  0.0  0.0  0.022993  0.0  0.0  0.010451  0.0  0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a66190c1-edb6-4bb8-acd0-47ed7cd7bd38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>design</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filter</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feed</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lid</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lift</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fish</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>drop</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>food</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>way</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.011162</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.022993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>door</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.022993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a66190c1-edb6-4bb8-acd0-47ed7cd7bd38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a66190c1-edb6-4bb8-acd0-47ed7cd7bd38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a66190c1-edb6-4bb8-acd0-47ed7cd7bd38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Score"
      ],
      "metadata": {
        "id": "nnToFooWJLnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TED_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6966
        },
        "id": "f0gs1u_yUcBn",
        "outputId": "d35f4482-2df8-40a6-97ce-aab92e4d0182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       document list  \\\n",
              "0  I have taken in many abandoned cats over the y...   \n",
              "1  This tea is just ok. Not offensive, but it doe...   \n",
              "2  I do not know what they were thinking with all...   \n",
              "3  I purchased this mat to go with the omega paw ...   \n",
              "4  I purchased this aquarium for my 2 year old's ...   \n",
              "5  Well, I was pleasantly surprised when I actual...   \n",
              "6  I just wanted to aknowledge a great customer e...   \n",
              "7  My wife and I love this gate! We live in an ex...   \n",
              "8  I have tried a LOT of automatic litter boxes o...   \n",
              "9  I love this thing. We bought it after our neig...   \n",
              "\n",
              "                                       sentence_list  Sentence_count  \\\n",
              "0  ['I have taken in many abandoned cats over the...              18   \n",
              "1  ['This tea is just ok', \" Not offensive, but i...              13   \n",
              "2  ['I do not know what they were thinking with a...              12   \n",
              "3  ['I purchased this mat to go with the omega pa...              12   \n",
              "4  [\"I purchased this aquarium for my 2 year old'...              12   \n",
              "5  [\"Well, I was pleasantly surprised when I actu...              12   \n",
              "6  ['I just wanted to aknowledge a great customer...              11   \n",
              "7  ['My wife and I love this gate! We live in an ...              11   \n",
              "8  ['I have tried a LOT of automatic litter boxes...              11   \n",
              "9  ['I love this thing', ' We bought it after our...              11   \n",
              "\n",
              "                                          one_String  \\\n",
              "0  I have taken in many abandoned cats over the y...   \n",
              "1  This tea is just ok  Not offensive, but it doe...   \n",
              "2  I do not know what they were thinking with all...   \n",
              "3  I purchased this mat to go with the omega paw ...   \n",
              "4  I purchased this aquarium for my 2 year old's ...   \n",
              "5  Well, I was pleasantly surprised when I actual...   \n",
              "6  I just wanted to aknowledge a great customer e...   \n",
              "7  My wife and I love this gate! We live in an ex...   \n",
              "8  I have tried a LOT of automatic litter boxes o...   \n",
              "9  I love this thing  We bought it after our neig...   \n",
              "\n",
              "                               documents_removepunct  \\\n",
              "0  I have taken in many abandoned cats over the y...   \n",
              "1  This tea is just ok  Not offensive but it does...   \n",
              "2  I do not know what they were thinking with all...   \n",
              "3  I purchased this mat to go with the omega paw ...   \n",
              "4  I purchased this aquarium for my 2 year olds g...   \n",
              "5  Well I was pleasantly surprised when I actuall...   \n",
              "6  I just wanted to aknowledge a great customer e...   \n",
              "7  My wife and I love this gate We live in an ext...   \n",
              "8  I have tried a LOT of automatic litter boxes o...   \n",
              "9  I love this thing  We bought it after our neig...   \n",
              "\n",
              "                                lower_cased_document  \\\n",
              "0  i have taken in many abandoned cats over the y...   \n",
              "1  this tea is just ok  not offensive but it does...   \n",
              "2  i do not know what they were thinking with all...   \n",
              "3  i purchased this mat to go with the omega paw ...   \n",
              "4  i purchased this aquarium for my 2 year olds g...   \n",
              "5  well i was pleasantly surprised when i actuall...   \n",
              "6  i just wanted to aknowledge a great customer e...   \n",
              "7  my wife and i love this gate we live in an ext...   \n",
              "8  i have tried a lot of automatic litter boxes o...   \n",
              "9  i love this thing  we bought it after our neig...   \n",
              "\n",
              "                                     tokennized_docs  \\\n",
              "0  ['i', 'have', 'taken', 'in', 'many', 'abandone...   \n",
              "1  ['this', 'tea', 'is', 'just', 'ok', 'not', 'of...   \n",
              "2  ['i', 'do', 'not', 'know', 'what', 'they', 'we...   \n",
              "3  ['i', 'purchased', 'this', 'mat', 'to', 'go', ...   \n",
              "4  ['i', 'purchased', 'this', 'aquarium', 'for', ...   \n",
              "5  ['well', 'i', 'wa', 'pleasantly', 'surprised',...   \n",
              "6  ['i', 'just', 'wanted', 'to', 'aknowledge', 'a...   \n",
              "7  ['my', 'wife', 'and', 'i', 'love', 'this', 'ga...   \n",
              "8  ['i', 'have', 'tried', 'a', 'lot', 'of', 'auto...   \n",
              "9  ['i', 'love', 'this', 'thing', 'we', 'bought',...   \n",
              "\n",
              "                                        no_stopwords  \n",
              "0  ['taken', 'abandoned', 'cat', 'year', 'product...  \n",
              "1  ['tea', 'ok', 'offensive', 'doesnt', 'taste', ...  \n",
              "2  ['know', 'thinking', 'reformulations', 'excell...  \n",
              "3  ['purchased', 'mat', 'omega', 'paw', 'roll', '...  \n",
              "4  ['purchased', 'aquarium', '2', 'year', 'old', ...  \n",
              "5  ['wa', 'pleasantly', 'surprised', 'actually', ...  \n",
              "6  ['wanted', 'aknowledge', 'great', 'customer', ...  \n",
              "7  ['wife', 'love', 'gate', 'live', 'extremely', ...  \n",
              "8  ['tried', 'lot', 'automatic', 'litter', 'box',...  \n",
              "9  ['love', 'thing', 'bought', 'neighbor', 'rente...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84f0a1fc-1355-442a-a491-cdb92bc004f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document list</th>\n",
              "      <th>sentence_list</th>\n",
              "      <th>Sentence_count</th>\n",
              "      <th>one_String</th>\n",
              "      <th>documents_removepunct</th>\n",
              "      <th>lower_cased_document</th>\n",
              "      <th>tokennized_docs</th>\n",
              "      <th>no_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have taken in many abandoned cats over the y...</td>\n",
              "      <td>['I have taken in many abandoned cats over the...</td>\n",
              "      <td>18</td>\n",
              "      <td>I have taken in many abandoned cats over the y...</td>\n",
              "      <td>I have taken in many abandoned cats over the y...</td>\n",
              "      <td>i have taken in many abandoned cats over the y...</td>\n",
              "      <td>['i', 'have', 'taken', 'in', 'many', 'abandone...</td>\n",
              "      <td>['taken', 'abandoned', 'cat', 'year', 'product...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This tea is just ok. Not offensive, but it doe...</td>\n",
              "      <td>['This tea is just ok', \" Not offensive, but i...</td>\n",
              "      <td>13</td>\n",
              "      <td>This tea is just ok  Not offensive, but it doe...</td>\n",
              "      <td>This tea is just ok  Not offensive but it does...</td>\n",
              "      <td>this tea is just ok  not offensive but it does...</td>\n",
              "      <td>['this', 'tea', 'is', 'just', 'ok', 'not', 'of...</td>\n",
              "      <td>['tea', 'ok', 'offensive', 'doesnt', 'taste', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I do not know what they were thinking with all...</td>\n",
              "      <td>['I do not know what they were thinking with a...</td>\n",
              "      <td>12</td>\n",
              "      <td>I do not know what they were thinking with all...</td>\n",
              "      <td>I do not know what they were thinking with all...</td>\n",
              "      <td>i do not know what they were thinking with all...</td>\n",
              "      <td>['i', 'do', 'not', 'know', 'what', 'they', 'we...</td>\n",
              "      <td>['know', 'thinking', 'reformulations', 'excell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I purchased this mat to go with the omega paw ...</td>\n",
              "      <td>['I purchased this mat to go with the omega pa...</td>\n",
              "      <td>12</td>\n",
              "      <td>I purchased this mat to go with the omega paw ...</td>\n",
              "      <td>I purchased this mat to go with the omega paw ...</td>\n",
              "      <td>i purchased this mat to go with the omega paw ...</td>\n",
              "      <td>['i', 'purchased', 'this', 'mat', 'to', 'go', ...</td>\n",
              "      <td>['purchased', 'mat', 'omega', 'paw', 'roll', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I purchased this aquarium for my 2 year old's ...</td>\n",
              "      <td>[\"I purchased this aquarium for my 2 year old'...</td>\n",
              "      <td>12</td>\n",
              "      <td>I purchased this aquarium for my 2 year old's ...</td>\n",
              "      <td>I purchased this aquarium for my 2 year olds g...</td>\n",
              "      <td>i purchased this aquarium for my 2 year olds g...</td>\n",
              "      <td>['i', 'purchased', 'this', 'aquarium', 'for', ...</td>\n",
              "      <td>['purchased', 'aquarium', '2', 'year', 'old', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Well, I was pleasantly surprised when I actual...</td>\n",
              "      <td>[\"Well, I was pleasantly surprised when I actu...</td>\n",
              "      <td>12</td>\n",
              "      <td>Well, I was pleasantly surprised when I actual...</td>\n",
              "      <td>Well I was pleasantly surprised when I actuall...</td>\n",
              "      <td>well i was pleasantly surprised when i actuall...</td>\n",
              "      <td>['well', 'i', 'wa', 'pleasantly', 'surprised',...</td>\n",
              "      <td>['wa', 'pleasantly', 'surprised', 'actually', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I just wanted to aknowledge a great customer e...</td>\n",
              "      <td>['I just wanted to aknowledge a great customer...</td>\n",
              "      <td>11</td>\n",
              "      <td>I just wanted to aknowledge a great customer e...</td>\n",
              "      <td>I just wanted to aknowledge a great customer e...</td>\n",
              "      <td>i just wanted to aknowledge a great customer e...</td>\n",
              "      <td>['i', 'just', 'wanted', 'to', 'aknowledge', 'a...</td>\n",
              "      <td>['wanted', 'aknowledge', 'great', 'customer', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>My wife and I love this gate! We live in an ex...</td>\n",
              "      <td>['My wife and I love this gate! We live in an ...</td>\n",
              "      <td>11</td>\n",
              "      <td>My wife and I love this gate! We live in an ex...</td>\n",
              "      <td>My wife and I love this gate We live in an ext...</td>\n",
              "      <td>my wife and i love this gate we live in an ext...</td>\n",
              "      <td>['my', 'wife', 'and', 'i', 'love', 'this', 'ga...</td>\n",
              "      <td>['wife', 'love', 'gate', 'live', 'extremely', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I have tried a LOT of automatic litter boxes o...</td>\n",
              "      <td>['I have tried a LOT of automatic litter boxes...</td>\n",
              "      <td>11</td>\n",
              "      <td>I have tried a LOT of automatic litter boxes o...</td>\n",
              "      <td>I have tried a LOT of automatic litter boxes o...</td>\n",
              "      <td>i have tried a lot of automatic litter boxes o...</td>\n",
              "      <td>['i', 'have', 'tried', 'a', 'lot', 'of', 'auto...</td>\n",
              "      <td>['tried', 'lot', 'automatic', 'litter', 'box',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I love this thing. We bought it after our neig...</td>\n",
              "      <td>['I love this thing', ' We bought it after our...</td>\n",
              "      <td>11</td>\n",
              "      <td>I love this thing  We bought it after our neig...</td>\n",
              "      <td>I love this thing  We bought it after our neig...</td>\n",
              "      <td>i love this thing  we bought it after our neig...</td>\n",
              "      <td>['i', 'love', 'this', 'thing', 'we', 'bought',...</td>\n",
              "      <td>['love', 'thing', 'bought', 'neighbor', 'rente...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84f0a1fc-1355-442a-a491-cdb92bc004f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-84f0a1fc-1355-442a-a491-cdb92bc004f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-84f0a1fc-1355-442a-a491-cdb92bc004f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#no_stopwords\n",
        "print(FS_df.loc['pill', 0])\n",
        "tf=termFrequency('pill',All_docs[0])\n",
        "idf_term=idf['pill']\n",
        "Score=tf*idf_term\n",
        "print(Score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QBSMvZyQZ0q",
        "outputId": "4fb973d3-b482-4990-c808-1f97279cf2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.040981031700582204\n",
            "0.11751165033309477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Score_cal(x,doc):\n",
        "  tf=termFrequency(x,doc)\n",
        "  idf_term=idf[x]\n",
        "  Score=tf*idf_term\n",
        "  #print(Score)\n",
        "  return Score\n"
      ],
      "metadata": {
        "id": "CrAEHVOGuxNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_check=eval(TED_data.iloc[0]['no_stopwords'])\n",
        "print(to_check)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljTlVoCCtobI",
        "outputId": "c53a934d-29ae-40fc-d7d8-5670c1780e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['taken', 'abandoned', 'cat', 'year', 'product', 'generic', 'version', 'stuff', 'vet', 'effective', 'usually', 'away', 'treatment', 'treatment', 'sure', 'live', 'mobile', 'home', 'park', 'pet', 'allowed', 'ha', 'pet', 'parasite', 'soil', 'product', 'stock', 'home', 'sign', 'tapeworm', 'stuff', 'come', 'cabinet', 'medicate', 'cat', 'hyperthyroidism', 'usegreenies', 'pill', 'pocket', 'cat', 'salmon', '1', '6', 'ounce', 'cat', 'love', 'force', 'pill', 'place', '12', 'tablet', '1', 'pill', 'pocket', 'struggling', 'fuss', 'chicken', 'duck', 'flavor', 'tapeworm', 'come', 'flea', 'use', 'good', 'flea', 'med', 'sure', 'vacuum', 'carpet', 'pet', 'area', 'wash', 'bedding', 'like', 'clean', 'cat', 'box', 'replace', 'litter', 'reduce', 'possibility', 'reinfestation', 'oh', 'yeah', 'dont', 'forget', 'cardboard', 'cat', 'scratcher', 'good', 'time', 'replace']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_list_sent(i,DOC):\n",
        "  doc_split=DOC[i].split(\" \")\n",
        "  \n",
        "  score_list=[]\n",
        "  for x in doc_split:\n",
        "    \n",
        "    if x in to_check:\n",
        "      #print('in',x)\n",
        "      s=Score_cal(x,All_docs[4])\n",
        "      score_list.append(s)\n",
        "    else:\n",
        "      #print('not in',x)\n",
        "      continue\n",
        "  return score_list"
      ],
      "metadata": {
        "id": "786S-EsJLpbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DOC=eval(TED_data.iloc[4]['sentence_list'])\n",
        "print(DOC)\n",
        "\n",
        "\n",
        "for i in range(len(DOC)):\n",
        "  print(DOC[i])\n",
        "  List=score_list_sent(i,DOC)\n",
        "  final_sent_score_sum=np.sum(List)\n",
        "  final_sent_score_prod=np.prod(List)\n",
        "  print(List)\n",
        "  print(final_sent_score_sum)\n",
        "  print(final_sent_score_prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asBHiQ6FOMiq",
        "outputId": "1b669d66-c0d1-452f-d924-bb4014142535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"I purchased this aquarium for my 2 year old's goldfish\", ' It seemed like a good design in the store', \"Also didn't read many negative reviews\", ' All integrated filter and water circulator', ' great! They tellyou to replace the filter every week or few weeks, so they make a nice little door on the cover forthe purpose', \" Then I went to feed the fish! There's no way to feed the fish through the cover\", ' Youhave to lift the entire lid off and drop in the food then re-align the lid on the base', ' Lame! Why wouldsomeone design something to be convenient for an occasional inconvenience and not designanything for a task done daily (or more)? After emailing the company first to question the design,I was told in response to lift the filter changing door and feed through there', ' Great! They give a halfinch of clearance with a crossbar in the way', ' So I can barely drop in some food and it lands on thecrossbar getting nasty', ' When I responded (much like my review) I never heard back', \" I guess thecompany agrees with me and were speechless! We'll see if the next design actually makes moresense for the user and not the designer\"]\n",
            "I purchased this aquarium for my 2 year old's goldfish\n",
            "[0.03877884460992127]\n",
            "0.03877884460992127\n",
            "0.03877884460992127\n",
            " It seemed like a good design in the store\n",
            "[0.07755768921984255, 0.03877884460992127]\n",
            "0.11633653382976382\n",
            "0.00300759757856084\n",
            "Also didn't read many negative reviews\n",
            "[]\n",
            "0.0\n",
            "1.0\n",
            " All integrated filter and water circulator\n",
            "[]\n",
            "0.0\n",
            "1.0\n",
            " great! They tellyou to replace the filter every week or few weeks, so they make a nice little door on the cover forthe purpose\n",
            "[0.03877884460992127]\n",
            "0.03877884460992127\n",
            "0.03877884460992127\n",
            " Then I went to feed the fish! There's no way to feed the fish through the cover\n",
            "[]\n",
            "0.0\n",
            "1.0\n",
            " Youhave to lift the entire lid off and drop in the food then re-align the lid on the base\n",
            "[]\n",
            "0.0\n",
            "1.0\n",
            " Lame! Why wouldsomeone design something to be convenient for an occasional inconvenience and not designanything for a task done daily (or more)? After emailing the company first to question the design,I was told in response to lift the filter changing door and feed through there\n",
            "[]\n",
            "0.0\n",
            "1.0\n",
            " Great! They give a halfinch of clearance with a crossbar in the way\n",
            "[]\n",
            "0.0\n",
            "1.0\n",
            " So I can barely drop in some food and it lands on thecrossbar getting nasty\n",
            "[]\n",
            "0.0\n",
            "1.0\n",
            " When I responded (much like my review) I never heard back\n",
            "[0.07755768921984255]\n",
            "0.07755768921984255\n",
            "0.07755768921984255\n",
            " I guess thecompany agrees with me and were speechless! We'll see if the next design actually makes moresense for the user and not the designer\n",
            "[]\n",
            "0.0\n",
            "1.0\n"
          ]
        }
      ]
    }
  ]
}